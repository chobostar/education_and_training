https://github.com/killer-sh/cks-course-environment

- Security combines many different things
- Env change security cannot stay in a certain stage
- Attackers have advantage
  - they decide time
  - they pick what to attack, like weakest link

Principles
- Defense in Depth
- Least Privilege
- Limiting the Attack Surface

Redundancy is good... in security.

Host OS Sec:
- k8s node should only do one thing k8s
- reduce attack surface
  - remove unnecessary applicatios
  - keep up to date
- runtime security tools
- find and indentify malicous processes
- restrict iam/ssh access


Application security:
- use secrets / no hardcoede credentials
- RBAC
- Container Sandboxing
- Container Hardening
  - Attack surface
  - Run as user
  - Readonly filesystem
- Vulnerability Scanning
- mTLS / ServiceMeshes

https://www.youtube.com/watch?v=wqsUfvRyYpw


https://console.cloud.google.com/

$ gcloud compute ssh cks-master
$ gcloud compute ssh cks-worker
$ gcloud compute instances stop cks-master
$ gcloud compute instances stop cks-worker

# All You Need to Know About Certificates in Kubernetes
https://www.youtube.com/watch?v=gXz4cq3PKdg

# Kubernetes Components
https://kubernetes.io/docs/concepts/overview/components

# PKI certificates and requirements
https://kubernetes.io/docs/setup/best-practices/certificates

Container
- collection of one or multiple applications
- includes all its dendendencies
- just a process runs on the linux kernel


User Space(Application, Libraries) - Kernel Space (Syscall Interface, Linux Kernel) - Hardware

Namespaces isolate processes:
- PID
- Mount
- Network
- User


# What have containers done for you lately?
https://www.youtube.com/watch?v=MHv6cWjvQjM


Network policies also applies to DNS resolution

---
Ingress

Pod nginx
create nginx config comfortable via K8s yaml resources

$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.47.0/deploy/static/provider/baremetal/deploy.yaml
$ k create secret tls secure-ingress --cert=cert.pem --key=key.pem
$ openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes

$ curl https://secure-ingress.com:31837/service2 -kv --resolve secure-ingress.com:31837:34.118.99.111

---
CIS Benchmarks

google.com -> cis benchmarks kubernetes

https://www.cisecurity.org/benchmark/kubernetes/


https://github.com/aquasecurity/kube-bench/blob/main/docs/running.md

$ docker run --pid=host -v /etc:/etc:ro -v /var:/var:ro -t aquasec/kube-bench:latest --version 1.21

https://cloud.google.com/kubernetes-engine/docs/concepts/cis-benchmarks

# talk about CIS
https://www.youtube.com/watch?v=53-v3stlnCo

https://github.com/docker/docker-bench-security
---

extract files from container there is no sh/bash:

$ docker ps | grep apiserver
f9721d3bd414   4d217480042e             "kube-apiserver --adâ€¦"   2 hours ago   Up 2 hours             k8s_kube-apiserver_kube-apiserver-cks-master_kube-system_e7941a0523b7b0cb6f62e129716d9db3_0
a5ca127fbb6a   k8s.gcr.io/pause:3.4.1   "/pause"                 2 hours ago   Up 2 hours             k8s_POD_kube-apiserver-cks-master_kube-system_e7941a0523b7b0cb6f62e129716d9db3_0

$ docker cp f9721d3bd414:/ container-fs

$ sha512sum ...
---

RBAC

specify what is allowed

resources:
- namespaced ($ kubectl api-resources --namespaced=true)
- non-namespaced ($ kubectl api-resources --namespaced=false)


ClusterRole
ClusterRoleBinding
be careful - they apply to all current and future namespaced and non-namespaced resources

permissions are additive

always test your rbac roles:
$ kubectl auth can-i delete deployment --as jane -A

Account:
- serviceacccount (there is a serviceaccount resource, managed by the k8s api)
- normal user (there is no k8s user resource, it is assumed that a cluster-independent service manages normal users)

There is no way to invalidate a certifacate
If a certificate has been leaked:
- remove all access via RBAC
- username cannot be used until cert expired
- create new CA and re-issue all certs (!!!)

$ k config set-credentials jane --client-key=jane.key --client-certificate=jane.crt
$ k config set-credentials jane --client-key=jane.key --client-certificate=jane.crt --embed-certs

$ k config set-context jane --user=jane --cluster=kubernetes
$ k config use-context jane

---
serviceaccount

automountServiceAccountToken: false
---
request flow (from human user, or pod sa):
- authentication (who are you?)
- authorization (are you allowd to create pod?)
- admission control (has the limit of pods been reached?)

restrictions:
- don't allow anonymous access 
- close incsecure port
- don't expose apisercer to the outside
- restrict access from Nodes to API (NodeRestriction)
- prevent unathorized access (RBAC)
- prevent pods from accessing API
- apiserver port behind firewall / allowed ip ranges (cloud provider)

enable/disable anon access:
kube-apiserver --anonymous-auth=false


kubectl request -> https -> api server

insecure access

enable insecure port (impossible to set!):
$ docker logs 7294d704a6b9
Flag --insecure-port has been deprecated, This flag has no effect now and will be removed in v1.24.
Error: invalid port value 8080: only zero is allowed

how to manual request:
echo "base64 -d"-ed cert to ca, crt, key then execute:
$ curl https://10.186.0.4:6443 --cacert ca --cert crt --key key

external api server access:
$ k edit svc kubernetes

set svc from ClusterIP to NodePort, then try remote access:
$ kubectl --kubeconfig trash/conf get pods
Unable to connect to the server: x509: certificate is valid for 10.96.0.1, 10.186.0.4, not 34.118.123.75

add entry for /etc/hosts and fix your kubeconfig

NodeRestriction
Admission Controller:
- kube-apiserver --enable-admission-plugins=NodeRestriction
- Limits the Node labels a kubelet can modify

Ensure secure workload isolation via labels:
- No one can pretend to be a "secure" node and schedule secure pods

kube-apiserver --enable-admission-plugins=NodeRestriction

on worker node:
$ export KUBECONFIG=/etc/kubernetes/kubelet.conf

root@cks-worker:~# k label node cks-worker cks/test=yes
node/cks-worker labeled
root@cks-worker:~# k label node cks-worker node-restriction.kubernetes.io/test=yes
Error from server (Forbidden): nodes "cks-worker" is forbidden: is not allowed to modify labels: node-restriction.kubernetes.io/test

so protected prefix is "node-restriction.kubernetes.io/"
---
Update Kubernetes:
- support
- security fixes
- bug fixes
- stay up to date for dependencies

How to upgrade a cluser:
- First upgtade the master components
- Then the worker components
- Components same minor version as apiserver

1. kubectl drain
2. do the upgrade
3. kubectl uncordon

- Pod gracePeriod / Terminating state
- Pod Lifecycle Events
- PodDisruptionBudget
---
Manage k8s secrets

https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-environment-variables

$ docker inspect d13bdfab252c | grep -i password
$ docker ps d13bdfab252c:/etc/secret1 secret1

$ ETCDCTL_API=3 etcdctl ... endpoint health
$ ETCDCTL_API=3 etcdctl ... get /registry/secrets/default/secret2
$ ETCDCTL_API=3 etcdctl ... get /registry/secrets/default/secret1

encrypt etcd
--encryption-provider-config
kind: EncryptionConfiguration

$ cat /etc/kubernetes/pki/etcd/enc.conf 
apiVersion: apiserver.config.k8s.io/v1
kind: EncryptionConfiguration
resources:
  - resources:
    - secrets
    providers:
    - aescbc:
        keys:
        - name: key1
          secret: 4beqm7YvYqwehRpTzeIacTbdX9le857/vr2qkyEN9Vk=
    - identity: {}

$ kubectl get secrets --all-namespaces -o json | kubectl replace -f -

$ k -n kube-system exec etcd-cks-master -- etcdctl --cert=/etc/kubernetes/pki/etcd/peer.crt --key=/etc/kubernetes/pki/etcd/peer.key --cacert=/etc/kubernetes/pki/etcd/ca.crt get /registry/secrets/default/secret1 | hexdump -C

https://kubernetes.io/docs/concepts/configuration/secret/#risks
https://www.youtube.com/watch?v=f4Ru6CPG1z4
https://www.cncf.io/webinars/kubernetes-secrets-management-build-secure-apps-faster-without-secrets
---

Container Runtime Sandboxes

sandbox ?
- playground when implementing an API
- simulated testing environment
- development server
- security layer to reduce attack surface

container -> system calls -> kernel -> hardware
container -> sandbox -> system calls -> kernel -> hardware

sandbox comes not for free:
- more resources
- might be better for smaller containers
- not good for syscall heavy workloads
- no direct access to hardware

"dirty cow" exploit

OCI - Open Container Initiative
- OCI
- LF project to design open standarts for virtualization
- Specification
  - runtime
  - image
  - distribution
- Runtime
  - runc

$ crictl -h

katacontainer - additional isolation with a lightweight VM and individual kernels:
- strong separation layer
- runs every container in its own private VM (hypervisor based)
- QEMU as default
  - needs virtualisation, like nested

gVisor - user-space kernel for containers
- another layer of separation
- NOT hypervisor/VM based
- simulates kernel syscalls with limited functionality
- runtime called runsc

different output: "$ dmesg -T"

---
OS Level Security Domains

Define privilege and access control for Pod/Container:
- userID and groupID
- Run privileged or unprivileged
- Linux Capabilities

Privileged means that container user 0 (root) is directly mapped to host user 0 (root)

PodSecurityPolicy
kube-apiserver --enable-admission-plugins=PodSecurityPolicy

allow default sa to see psp !!!

$ kubectl create role psp-access --verb=use --resource=podsecuritypolicies

Open Policy Agent - more flexible than PSP
---

mTLS

proxy side-container needs pod capabilites:
    securityContext:
      capabilities:
        add: ["NET_ADMIN"]
---
Open Policy Agent

custom policies

- Not k8s specific
- easy implementation of policies (Rego langauge)
- Works with JSON/YAML
- In k8s it uses Admission Controllers
- Does not know concepts like pods or deployments

OPA Gatekeeper - provides k8s CRDs

- contraint template
- contraint (pods must have label X, namespace must have label Y)

install gt:
kubectl create -f https://raw.githubusercontent.com/killer-sh/cks-course-environment/master/course-content/opa/gatekeeper.yaml

deny all:
https://github.com/killer-sh/cks-course-environment/tree/master/course-content/opa/deny-all

https://play.openpolicyagent.org/

about OPA:
https://www.youtube.com/watch?v=RDWndems-sk
---

Image footprint

multistage containers - image contains only last stage:
```
FROM ubuntu
ARG DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y golang-go
COPY app.go .
RUN CGO_ENABLED=0 go build app.go

FROM alpine
COPY --from=0 /app .
CMD ["./app"]
```

- use specific tags! to increase reliability
- don't run as root! (RUN addgroup -S appgroup && adduser -S appuser -G appgroup -h /home/appuser; USER appuser)
- make filesystem read only (RUN chmod a-w /etc)
- remove shell access (RUN rm -rf /bin/*)

https://docs.docker.com/develop/develop-images/dockerfile_best-practices

---
Static Analysis
- always define resource requests and limits
- pods should never use the default ServiceAccount (depends on)

Kubesec (https://kubesec.io/)
- security risk analysis for k8s resources
- opensource
- opinionated! fixed set of rules (security best practices)
- run as:
  - binary
  - docker container
  - kubectl plugin
  - admission controller (kubesec-webhook)

docker run -i kubesec/kubesec:512c5e0 scan /dev/stdin < kubesec-test.yaml

Conftest - OPA

$ docker run --rm -v $(pwd):/project openpolicyagent/conftest test deploy.yaml

$cat policy/deployment.rego 
# from https://www.conftest.dev
package main

deny[msg] {
  input.kind = "Deployment"
  not input.spec.template.spec.securityContext.runAsNonRoot = true
  msg = "Containers must not run as root"
}

deny[msg] {
  input.kind = "Deployment"
  not input.spec.selector.matchLabels.app
  msg = "Containers must provide app label for pod selectors"
}
---

Image Vulnerability Scanning
targets:
- remotely accessible application in container
- local application inside container

results:
- privilege escalation
- information leaks
- DDOS

known image vulnerabilities database:
- https://cve.mitre.org
- https://nvd.nist.gov

Clair
- open source project
- static analysis of vulneratibilites in app containers
- ingest vulnerability metadata from a configured set of sources
- provides API

Trivy
- open source project
- "a simply and comprehensive vulnerability scanner for containers and other artifacts, suitable for CI"
- simple, easy and fast

https://github.com/aquasecurity/trivy#docker

$ docker run ghcr.io/aquasecurity/trivy:latest image nginx:latest
---

Secure Supply Chain

$ k create secret docker-registry my-private-registry ...
$ k patch serviceaccount default -p '{"imagePullSecrets": [{"name": "my-private-registry"}]}'

$ k get pod -A -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\n' | sort | uniq
bash
docker.io/jettech/kube-webhook-certgen:v1.5.1
docker.io/weaveworks/weave-kube:2.8.1
docker.io/weaveworks/weave-npc:2.8.1
httpd
k8s.gcr.io/coredns/coredns:v1.8.0
k8s.gcr.io/etcd:3.4.13-0
k8s.gcr.io/ingress-nginx/controller:v0.46.0@sha256:52f0058bed0a17ab0fb35628ba97e8d52b5d32299fbc03cc0f6c7b9ff036b61a
k8s.gcr.io/kube-apiserver:v1.21.0
k8s.gcr.io/kube-controller-manager:v1.21.0
k8s.gcr.io/kube-proxy:v1.21.0
k8s.gcr.io/kube-scheduler:v1.21.0
nginx
ubuntu

---
Behavioral Analytics at host and container level

strace:
- intercepts and logs system calls made by a process
- log and display signals received by a process
- diagnostic, learning, debugging

summary:
$ strace -cw ls

/proc directory

strace Kubernetes etcd


$ cd /proc/$(pgrep etcd)/fd
$ ls -lh
$ tail 7
$ cat 7 | strings | grep '<secret>'

view secrets from env:
$ pstree -p
$ cat /proc/5935/environ

Falco - cloud native runtine security (CNCF)
- Access - deep kernel tracing built on the linux kernel
- Assert
  - describe security rules against a system (+ default ones)
  - detect unwanted behaviour
- Action
  - Automated respond to a security violations
  
$ tail -f /var/log/syslog | grep falco
$ k exec -it pod -- bash
  
Jul 25 16:53:12 cks-worker falco: 16:53:12.465349379: Notice A shell was spawned in a container with an attached terminal (user=root user_loginuid=-1 k8s_apache_apache_default_ae5acab5-4a1a-421e-b414-2c4f25bdee5f_0 (id=bd15347d8321) shell=bash parent=runc cmdline=bash terminal=34816 container_id=bd15347d8321 image=httpd)

Jul 25 16:54:19 cks-worker falco: 16:54:19.308569457: Error File below /etc opened for writing (user=root user_loginuid=-1 command=bash parent=<NA> pcmdline=<NA> file=/etc/passwd program=bash gparent=<NA> ggparent=<NA> gggparent=<NA> container_id=bd15347d8321 image=httpd)

$ mcedit /etc/falco/falco_rules.yaml
---

Immutability of containers at runtime

why?
- advanced deployment methods
- easy rollback
- more reliability
- better security (on container level)

Enforce on container image level
- remove bash/shell
- make fs read-only
- run as user and non root

for example:
- CMD: chmod a-w -R / && nginx
- startupProbe: chmod a-w -R /
- enforce RO root filesystem: using SecurityContexts and PodSecurityPolicies

    startupProbe:
      exec:
        command:
        - rm
        - /bin/bash
      initialDelaySeconds: 1
      periodSeconds: 5

initContainer:
- read write to cache volume

mount emptyDir for write, use `readOnlyRootFilesystem: true`

$ docker run --read-only --tmpfs /run my-container
---

Auditing

why?
- did someone acces an important secret while it was not protected?
- when was the last time that user X did access cluster Y?
- does my CRD work properly?

kube-api stages:
- request received
- response started
- response complete
- panic

kube-apiserver ...
    - --audit-policy-file=/etc/kubernetes/audit/policy.yaml       # add
    - --audit-log-path=/etc/kubernetes/audit/logs/audit.log       # add
    - --audit-log-maxsize=500                                     # add
    - --audit-log-maxbackup=5                                     # add
    
$ cat /etc/kubernetes/audit/policy.yaml 
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata

logs:
$ cat /var/log/pods/


to refresh policy, need to stop and start kube-apiserver (not just delete pod)
---

Kernel Hardening

container isolation
- namespaces restrictings
- cgroup limits resources

AppArmor Profile Modes:
- Unconfined
- Complain
- Enforce

$ aa-status
$ apt-get install apparmor-utils
$ aa-genprof curl

$ cat /etc/apparmor.d/usr.bin.curl 
# Last Modified: Mon Jul 26 16:49:20 2021
#include <tunables/global>

/usr/bin/curl {
  #include <abstractions/base>

  /lib/x86_64-linux-gnu/ld-*.so mr,
  /usr/bin/curl mr,

}

$ aa-logprof

$ docker run --security-opt apparmor=docker-nginx nginx

- Container runtime needs to support AppArmor
- AppArmor needs to be installed on every node
- AppArmor profiles need to be available on every node
- AppArmor profiles are specified per container
  - done using annotations

annotations:  
  container.apparmor.security.beta.kubernetes.io/<container_name>: localhost/docker-nginx
  
Seccomp -> seccomp-bpf

$ docker run --security-opt seccomp=default.json nginx

# syscalls
https://www.youtube.com/watch?v=8g-NUUmCeGI

# AppArmor, SELinux Introduction 
https://www.youtube.com/watch?v=JFjXvIwAeVI

---
Reduce Attack Surface

Application:
- keep up to date
- update linux kernel
- remove not needed packages

Network:
- check and close open ports
- network behind firewall

IAM
- Run as user, not root
- Restrict user permission

Nodes that run Kubernetes
- Only purpose: run k8s components
  - Remove unnecessary services
- Nodes recycling
  - Nodes should be ephemeral
  - Created from images
  - Can be recycled any time (and fast if necessary)

Linux Distributions:
- Often include number of services
- Meant to help, to widen attack surface
- The more existing and running services, the more convenient (for attacker)
---
Reduce Attack Surface

$ systemctl stop snapd
$ systemctl list-units
$ systemctl disable snapd

vsftpd
smbd

prefer use listen only 127.0.0.1 interface

$ netstat -ntlp | grep 21
$ lsof -i :21

users
$ cat /etc/passwd

https://itnext.io/cks-exam-series-1-create-cluster-security-best-practices-50e35aaa67ae

---
Revise fo retake:
- Audit Logs and policy syntax
- AppArmor
- https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook
- ImagePolicyWebhook
- KubeAPI - anonymous access
