Главное отличие Kafka от сервисов очередей (например RabbitMQ или Amazon SQS):
- сообщения в Kafka не удаляются по мере их обработки консьюмерами;
- одни и те же сообщения могут быть обработаны сколько угодно раз, в том числе несколькими сервисами одновременно.

Структура данных:
- Key: "Alice"
- Value: "Registered on out website"
- Timestamp: "Jun. 25 20220 at 02:06 p"
- Headers: [{"X-Generated-By": "web-host-12.eu-west2.slurm.io"}]

Хрнятся в именованный топиках. Топик состоит 1 или из нескольких партиций. 
Сообщение я с одинаковыми ключами (Key) записываются в одну и ту же партицию - Murmurhash. Если ключ отсутствует - RoundRobin.

Кафка гарантирует очередност записи и чтения в рамках одной партиции. Данные записываются согласно replication factor.

У каждой партиции есть 1 брокер лидер, который принимает запись и отдает. У лидера может быть 0..N фолловеров, которые хранят реплики.
Сообщения всегда отправляются лиедру и, в общем случае, читаются с лидера.

Каждому записанному сообщению назнчается offset - уникальный, монотонно возращающий 64-bit unsigned int. Сообщение записывается в голову лога.

Данные не удаляются просле прочитывания. Удаляются согласно заданной конфигурации retension-a:
- retension.ms - минимальное время хранения сообщений
- retension.bytes - максимальный размер партиции

Длительность хранения не влияет на производительность Kafka.

Consumer Groups (CG)
- могут читать из нескольких топиков
- можно добавлять нескольких консумеров в группу при этом чтение из партиций распределятся
- идеально - количество партиций == количество консумеров
- если консумеров внутри группы > количество партиций, то он не будет читать вообще

внутри CG партиции назначаются уникально, чтобы избежать повторной обработки.

партиции - инструмент масштабирования

если какой-то консумер упадет - партиции распределятся между оставшимися консумерами в этой CG


Партиции можно добавлять в любой момент (консумера автоматически перераспределятся), но:
- нужно помнить про гарантию очередности в рамках одной партиции
  - если вы пишите сообщения с ключами и хэшируете номер партиции или номер сообщения исходя из общего числа, то при добавлении новой партиции вы можете сломать порядок этой записи 
- индивидуальные партиции нельзя удалить после создания

Нужно помниьт про конфигурацию auto.offset.reset в консьюмерах: при добавлении новой партии "на проде"
вы наверняка захотите прочитать данные с начала лога (auto.offset.reset=earliest). 
Иначе есть шанс потерять/не прочитать данные которые записались в новую партицию, 
до того как консумеры обновлять метаданные по топику и начнуть читать данные из этой партиции.

[!] Партиции не бесплатны:
- Каждая увеличивает время старта брокера и выбора лидеров после падения. Теоретический лимит на кластер 200k партиций для Kafka 2.0+

Можно добавлять разные CG на один и тот же топик.

Консумер делает commit offset-a с указаем:
- топика
- идентификатора партиции
- своей группы
- и оффсета

Брокер сохраняет это в своем топике __consumer_offsets, при рестарте консумера, тот запрашивает у брокера последний закоммиченный оффсет.

Если требуется пропустить ошибочное сообщение - https://en.wikipedia.org/wiki/Dead_letter_queue

Zookeepeer - распределенное хранилище, клиенты кафки напрямую к нему не соединяются

Broker controller - брокер отвечающий за выбор лидера партиции, знает в каком состоянии находятся лидеры партиций и их реплики



