Главное отличие Kafka от сервисов очередей (например RabbitMQ или Amazon SQS):
- сообщения в Kafka не удаляются по мере их обработки консьюмерами;
- одни и те же сообщения могут быть обработаны сколько угодно раз, в том числе несколькими сервисами одновременно.

Структура данных:
- Key: "Alice"
- Value: "Registered on out website"
- Timestamp: "Jun. 25 20220 at 02:06 p"
- Headers: [{"X-Generated-By": "web-host-12.eu-west2.slurm.io"}]

Хрнятся в именованный топиках. Топик состоит 1 или из нескольких партиций. 
Сообщение я с одинаковыми ключами (Key) записываются в одну и ту же партицию - Murmurhash. Если ключ отсутствует - RoundRobin.

Кафка гарантирует очередност записи и чтения в рамках одной партиции. Данные записываются согласно replication factor.

У каждой партиции есть 1 брокер лидер, который принимает запись и отдает. У лидера может быть 0..N фолловеров, которые хранят реплики.
Сообщения всегда отправляются лиедру и, в общем случае, читаются с лидера.

Каждому записанному сообщению назнчается offset - уникальный, монотонно возращающий 64-bit unsigned int. Сообщение записывается в голову лога.

Данные не удаляются просле прочитывания. Удаляются согласно заданной конфигурации retension-a:
- retension.ms - минимальное время хранения сообщений
- retension.bytes - максимальный размер партиции

Длительность хранения не влияет на производительность Kafka.

Consumer Groups (CG)
- могут читать из нескольких топиков
- можно добавлять нескольких консумеров в группу при этом чтение из партиций распределятся
- идеально - количество партиций == количество консумеров
- если консумеров внутри группы > количество партиций, то он не будет читать вообще

внутри CG партиции назначаются уникально, чтобы избежать повторной обработки.

партиции - инструмент масштабирования

если какой-то консумер упадет - партиции распределятся между оставшимися консумерами в этой CG




Партиции можно добавлять в любой момент (консумера автоматически перераспределятся), но:
- нужно помнить про гарантию очередности в рамках одной партиции
  - если вы пишите сообщения с ключами и хэшируете номер партиции или номер сообщения исходя из общего числа, то при добавлении новой партиции вы можете сломать порядок этой записи 
- индивидуальные партиции нельзя удалить после создания

Нужно помниьт про конфигурацию auto.offset.reset в консьюмерах: при добавлении новой партии "на проде"
вы наверняка захотите прочитать данные с начала лога (auto.offset.reset=earliest). 
Иначе есть шанс потерять/не прочитать данные которые записались в новую партицию, 
до того как консумеры обновлять метаданные по топику и начнуть читать данные из этой партиции.

[!] Партиции не бесплатны:
- Каждая увеличивает время старта брокера и выбора лидеров после падения. Теоретический лимит на кластер 200k партиций для Kafka 2.0+

Можно добавлять разные CG на один и тот же топик.

Консумер делает commit offset-a с указаем:
- топика
- идентификатора партиции
- своей группы
- и оффсета

Брокер сохраняет это в своем топике __consumer_offsets, при рестарте консумера, тот запрашивает у брокера последний закоммиченный оффсет.

Если требуется пропустить ошибочное сообщение - https://en.wikipedia.org/wiki/Dead_letter_queue

Zookeepeer - распределенное хранилище, клиенты кафки напрямую к нему не соединяются

Broker controller - брокер отвечающий за выбор лидера партиции, знает в каком состоянии находятся лидеры партиций и их реплики


Basic console commands

Создаем топик с регистрациями:
```
./bin/kafka-topics.sh --create --topic registrations --bootstrap-server localhost:9092
```

Посмотрим на его конфигурацию:
```
./bin/kafka-topics.sh --describe --topic registrations --bootstrap-server localhost:9092
```
Давайте запишем первое сообщение
```
./bin/kafka-console-producer.sh --topic registrations --bootstrap-server localhost:9092
>Hello world!
>Hello Slurm!
```

читать с `auto.offset.reset=earliest` или `--from-beginning`
```
./bin/kafka-console-consumer.sh --topic registrations --bootstrap-server localhost:9092 --consumer-property auto.offset.reset=earliest
```

можно задавать имя CG явно:
```
./bin/kafka-console-consumer.sh --topic registrations --group slurm --bootstrap-server localhost:9092 --consumer-property auto.offset.reset=earliest
```

посмотреть конфиги CG:
```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group slurm --describe
```
резетнуть:
```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group slurm --to-earliest --reset-offsets --execute --topic registrations
```
отключить авто-коммиты:
```
./bin/kafka-console-consumer.sh --topic registrations --bootstrap-server localhost:9092 --group slurm --consumer-property auto.offset.reset=earliest --consumer-property enable.auto.commit=false
```
alter topics:
```
./bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name registrations --alter --add-config retention.ms=60000
```

Кафка удаляет данные посегментно - проверят diff от максимального timestamp (если retension.ms указан). 
Может быть такое, что данные пишутся часто и пока rollup сегмента не случится в сегменте diff будет < retension.ms. 

Настройки rollup-a:
- segment.ms - период роллапа сегмента после открытия (default: 1 weak)
- segment.bytes - максимальный размер сегмента (default: 1GB)

Большая часть настроек Кафки может быть определена на 2-х уровнях:
- broker-level config - уровень сервеа, используется по-умолчанию (часто имеют префикс log.*)
- topic-level config - оверрайды для отдельных топиков, имеют более высокий приоритет

Полный перечень настроек здесь:
https://kafka.apache.org/documentation/#configuration

По-умолчанию, логи хранятся тут:
```
cd /tmp/kafka-logs/registrations-0/
```

Log Compaction - еще один механизм удаления. использует ключи сообщений, чтобы решить удалять или нет.
- cleanup.policy - delete для ретеншена по времени/размеру (включен по-умолчанию), compact для включения compaction

Довольно **трудоемкий** процесс, нагружает память, процессор и диск. 

**Не атомарен** - внутри партиции по-прежнему могут одновременно находиться несколько записей с одинаковым ключом.

**Оффсеты не меняются**, порядок записей остается прежним

Позволяет **"удалять" записи по ключу**, хорошо подходит для снэпшоттинга и восстановления последнего состояния системы после падения/перезагрузки
