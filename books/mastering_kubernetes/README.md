Kubernetes в действии. Марко Лукша
==================================

- [Kubernetes в действии. Марко Лукша](#kubernetes-----------------------)
  * [Глава 1. Знакомство с K8S](#------1--------------k8s)
    - [Запуск приложений в k8s](#--------------------k8s)
    - [Преимущества использования k8s](#---------------------------k8s)

## Глава 1. Знакомство с K8S

Монолиты имеют медленные циклы релизов и редко обновляются. Монолиты дробятся на микросервисы, чтобы разрабатываться независимо и быстро. 
Нужна автоматика по деплойменту, настройке, контролю и обработке аварийных сбоев. Именно здесь в игру вступает Kubernetes.

Kubernetes:
- разработчики деплоят свои приложения самостоятельно и так часто
- разработчикам для деплоя не требуется помощь системных администраторов
- помогает автоматически отслеживать и перемещать приложения в случае сбоев оборудования
- сисадмины - контроль за платформой k8s и остальной инфраструктурой
- k8s сама заботится о приложениях

DevOps - разработка, QA и сисадмины  сотрудничают на протяжении всего процесса
NoOps - разработчики деплоят, не зная об аппаратной инфраструктуре и не имея дела с сисадминами

K8s позволяет достичь NoOps.

Приложения изолируют свои среды через контейнеры. Виртуалки требуется индивидуальной настройки и управления, 
требуют траты человеческих ресурсов.

Каждая VM требует запускать свой набор системных процессов, который требует еще вычислительных ресурсов в дополнение, 
что требуется приложением. Контейнер выполняется в центральной ОС, без накладных расходов в виде доп ресурсов.

namespaces - каждый процесс видит свое персональное представление о системе (файлы, процессы, сетевые интерфейсы, hostname итд)
cgroups - ограничивает объем ресурсов, которые может потреблять процесс (cpu, ram, network throthput etc)

Компоненты K8s:
- control plane (master):
    - etcd - непрерывно сохраняетт конфигурацию кластера
    - сервер API - то с чем взаимодействует другие компоненты и человек
    - менеджер контроллеров - выполняет функции кластерного уровня, как репликация компонентов, отслеж нод, обработка отказов итд
    - планировщик - распределяет приложения по нодам
- Рабочий узел (kube node):
    - kubelet - агент, общаяется с сервером API и управляет контейнерами на своем узле
    - docker runtime
    - kube-proxy - балалнсирует нагрузку сетевого трафика между компонентами приложения

#### Запуск приложений в k8s

Сборка приложения в один или несколько контейнеров, отправка их в хранилище образов, а затем публикация описания приложения на сервере API K8s

Когда сервер API обрабатывает описание приложения, планировщик назначает указанные группы контейнеров доступным рабочим узлам, исходя из
вычислительных ресурсов, требуемых каждой группой, и нераспределенных ресурсов на каждом узле в данных момент.
Агент Kubelet на этих узлах затем поручает среде выполнения контейнеров (docker runtime) извлечь из хранилища требуемые
образы контейнеров и запустить контейнеры.

После запуска приложения k8s следит за тем, чтобы то состояние, в котором было развернуто приложение, всегда соответствовало указанному вами описанию.

Можно сообщить k8s, какие контейнеры предосталяют одну и ту же службу, и k8s обеспечит доступ ко всем контейрнерам по единому статическому IP и предоставит
доступ к этому адресу всем приложениям, работающим в кластере. Это делается через env vars, но можно и через DNS. kube-proxy обеспечивает балансировку нагрузки
подключений к службе во всех контейнерах, предоставляющих службу. IP-адрес службы остается постоянным, поэтому клиенты всегда могут подключаться к ее контейнерам, даже
если они перемещаются по кластеру.

#### Преимущества использования k8s
- Упрощение развертывания приложения
- Повышение эффективности задействования оборудования
- Проверка здоровья и самолечение
- Автоматическое масштабироваие
- Упрощение разработки приложений

## Глава 2. Первые шаги с Docker и Kubernetes

#### docker commands
```
$ docker build -t kubia .
$ docker run --name kubia-container -p 8080:8080 -d kubia
$ curl localhost:8080
$ docker ps
$ docker inspect kubia-container
$ docker exec -it kubia-container bash
$ docker stop kubia-container
$ docker rm kubia-container
$ docker tag kubia somename/kubia
$ docker push somename/kubia
```

#### k8s commands
```
$ minikube start
$ kubectl cluster-info
$ kubectl get nodes
$ kubectl describe node minikube
$ kubectl run kubia --image=somename/kubia --port=8080 --generator=run/v1
$ kubectl get pods
$ kubectl expose rc kubia --type=LoadBalancer --name kubia-http
$ minikube serivce kubia-http
$ kubectl get services
$ kubectl get svc
$ kubectl get replicationcontrollers
$ kubectl scale rc kubia --replicas=3
$ kubectl get rc
$ kubectl get pods
$ kubectl get pods -o wide
$ kubectl describe pod <podname>
$ minikube dashboard
```

## Глава 3. Модули: запуск контейнеров в Kubernetes

Модули - размещенная рядом группа контейнеров, основной строительный блок в k8s:
- частичная изоляция между контейнерами одного модуля - один linux namespace: Network, UTS 
- использует одно пространство ip-адресов и портов
- один loopback-интерфейс
- все модули видят друг друга по ip - плоская сеть под модулями

модули являются логическими хостами и ведут себя как физические хосты или виртуальные машиы в неконтейнерном мире. Процессы
запущенные в одном модуле, подобны процессам, запущенным на одной физической или виртуальной машине, за исключением того, что
каждый процесс инкапсулируется в контейнер.

(здесь масштабирование - подразумевается горизонатальное масштабирование)

как контейнеры должны быть сгруппированы в модули:
- они должны работать вместе или могут работать на разных хостах?
- представляют ли они собой единое целое или являются независимымми компонентами?
- они должны масштабироваться вместе или по отдельности?

Контейнер не должен выполнять несколько процессов. 
Модуль не должен содержать многочисленные контейнеры, если они не обязатятельно должны выполняться на одинаковой машине.

### Создание модулей из дескрипторов YAML и JSON

Модули и другие ресурсы K8s обычно создаются путеем публикации манифеста json или yaml в конечной точке k8s rest api. Более простые - kubectl run.

```
kubectl get po kubia-zxzij -o yaml
```

Почти во всех ресурсах k89s находятся три каждые секции:
- metadata - вклчюает имя, пространство имен, метки и другую информацию о модуле;
- spec - содержит фактическое описание содержимого модуля, напрмер контейнеры модуля, тома и другие данные;
- status - содержит текущую информацию о работающем модуле, как условие, в котором находится модуль описание и статус каждого контейнера, внутренний IP модуля, и другую базовую информацию.

```
kubectl explain pods
```
```
kubectl create -f kubia-manual.yaml
```

#### Label selectors

- содержит ли (или не содержит) ресурс метку с определенным ключом;
- содержит ли ресурс метку с определенным ключом и значением;
- содержил ли ресурс метку с определенным ключом, но со значением, не равным указанному вами;

```
kubectl get po - l creation_methoh=manual
kubectl get po -l env
kubectl get go -l '!env'
```

#### Резюме
- метки и селекторы меток следует использовать для организации моудлей и упрощения выполнения операций с несколькими модулями одновременно;
- метки и селекторы узлов можно использовать, чтобы назначать модули только тем узлам, котроые имеют определенные функциональные особенности;
- аннотации позволяют приклеклять более крупные блобы данных к модулям, и это делается либо пользователями, либо инструментами и библиотеками;
- пространства имен можно использовать для того, чтобы разные группы специалистов могли использовать тот же кластер, как если бы они использовали разные кластеры K8s;

## Глава 4. Контроллер репликации и другие контроллеры: развертывание управляемых модулей

livenessProbe - проверка текущей работоспособности контейнера
readynessProbe - проверка готовности

Они и используются в разных целях. Проверки могут быть с помощью одного из трех механизмов:
- проверка HTTP GET выполняется HTTP GET на IP-адрес, порт и путь контейнера, которые вы укажите, если ответ не HTTP 2xx и 3xx, контейнер будет перезапущен.
- проверка сокета TCP пытается открыть TCP-подключение к указнному порту контейнера. Если есть подключение, то успех. Иначе контейнер перезапускается.
- проверка Exec выполняет произвольную команду внутри контейнера, exit code 0 == успех, иначе считаются несработавшими

```
kubectl logs mypod --previous
```

Exit code 137. Процесс был заверешнен по внешнему сигналу. Число 137 - это сумма двух чисел: 128 + x, где x - номер сигнала, отправленнного процессу, который вызывал его завершение.
Здесь x == 9, число сигнала SIGKILL, т.е. процесс был убит принудительно.

Обязательно проверяйте только внутренние части приложения и ничего из того, что зависит от внешнего фактора. Например, livenessProbe не должна завершаться с ошибкой, когда
сервер не может подключиться к внутренней базе данных. Если основная причина находится в самой базе данных, перезапуск конейтера веб-сервеа проблему не устранит.

LivenessProbe не должны использоваться слишком много вычислительных ресурсов и не должны занимать слишком много времени.

ReplicationController - это ресурс K8s, который обеспечивает поддержание постоянной работы его модулей.

Цикл контроллера репликации:
1. Начало
2. Найти модули, совпадающие с селектором меток
3. Сравнить совпавшее количество модулей с требуемым, если мало, то п.4, если больше, то п.5, если в самый раз то п.6.
4. Создать доп модулей из текущего шаблона, далее п.6 
5. Удалить лишие модули, далее п.6
6. Вернуться в п.2

Части ReplicationController:
- селектор меток, определеюящие, какие модули находятся в области действия контроллера репликации;
- количество реплик, указывающее на требуемое количество модулей, которые должны быть запущены;
- шаблон модуля, используемый при создании новых реплик модуля;

ReplicationController deprecated. Теперь ReplicaSet.

ReplicaSet имеет более выразительные селекторы модуля, через matchExpressions:
- In
- NotIn
- Exists
- DoesNotExists

DaemonSet - запускают только одну реплику модуля на каждом узле, в том время как ReplicaSet разбрасывают их по всему кластеру случайным образом. Но можно повлиять на это - 
выполнять только на подмножестве всех узлов. Это делается путем задания свойства nodeSelector. Модули DaemonSet деплоятся в обход планировщикова - на них не распространяется unschedulable.

Job позволяет запускать модуль, контейнер которог он не перезапускатеся, когда процесс, запущенный внутри, заканчивается успешно. После этого модуль считается завершенным.
Модули, управляемые opb, переназначиются до тех пор, пока задания не завершатся успешно.

посмотреть завершившиеся тоже:
```
$ kubectl get po -a
```
```
$ kubectl get job
```
activeDeadlineSeconds - органичить время
backoffLimit - количество ретраев

CronJob - в назначенное время создает ресурс Job.

Может случиться так, что задание или модуль создается и выполнятеся относительно поздно. У вас может быть жесткое требование, чтобы задание не отставалло от расписания.
Для этого можно указать startingDeadlineSeconds в секции spec ресурса CronJob. Есои оно не запустится в течение startingDeadlineSeconds, то будет показано Failed.

В обычных условиях CronJob всегда создает всего одно задание для каждого выполнения, но может случиться так, чтоб два задания создаются одновременно или вообще не создаются.
Для борьбы с первой проблемой - задания должны быть идемпотентными. Что касается второго - убедитесь, что следующий запуск задания выполняет любую работу, которая должна была быть выполнена предыдущим (пропущенным) запуском.

#### Резюме
- если задать livenessProbe, то k8s будет перезапускать контейнер, как только он будет не здоров;
- модули не должны создавать напрямую (неотказоустойчиво как минимум);
- контролллеры репликации всегда поддерживаю требуемое количество реплик модуля;
- для горизонатального масштабирования модулей в rc достаточно указать ему желаемое количество реплик модуля;
- rc не владеют модулями, и модули при необходимости могут перемещаться между ними;
- rc создает новые модули из шаблона модуя. Измнение шаблона не влияет на существующие модули;
- rc deprecated. Теперь ReplicaSet (rs) и Deployments
- rc и rs назначают модули случайным узлам кластера, в то время как наборы демонов (DaemonSet) гарантируют, что каждый узел выполняет один экземпляр модуля, определнного в наборе демонов;
- модули, выполняющие пакетную задачу, должны создаваться посредством ресурса Job системы k8s, а не напрямую, или посредством контролера репликации, или анаологичным объектом;
- задания, которые должны выполняться, в будущем, могуть быть созданы с помощью ресурсов CronJob;